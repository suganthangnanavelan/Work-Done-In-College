{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVbwDSwfR3CY",
        "outputId": "f963e4b5-913a-4c2d-c13e-04faf794b259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag,word_tokenize\n",
        "import pandas as pd\n",
        "import math\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fpa(pi,state,transition,words):\n",
        "    alpha=[pi]\n",
        "    for t in range(1,len(words)+1):\n",
        "        val=0\n",
        "        temp=list()\n",
        "        for j in range(0,len(state)):\n",
        "            for i in range(0,len(state)):\n",
        "                ok=words[t-1]\n",
        "                val=val+(alpha[t-1][i]*state[i][j]*transition[i][ok-1])\n",
        "                print(\"i: \",i,\"t : \",t,\"j: \",j,\"val: \",val,\"ok value: \",ok)\n",
        "                print(alpha[t-1][i],\"*\",state[i][j],\"*\",transition[i][ok-1])\n",
        "            temp.append(val)\n",
        "            val=0\n",
        "            print(\"updated val: \",val,\"updated temp: \",temp,\"\\n\")\n",
        "            if(len(temp)==len(state)):\n",
        "                alpha.append(temp)\n",
        "    return sum(alpha[-1])"
      ],
      "metadata": {
        "id": "xIZ1yukLSCL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi=[1,0]\n",
        "state=[[0.4,0.6],[0.5,0.5]]\n",
        "transition=[[0.4,0.4,0.2],[0.3,0.4,0.3]]\n",
        "words=[3,2]\n",
        "\n",
        "\n",
        "ans=fpa(pi,state,transition,words)\n"
      ],
      "metadata": {
        "id": "rr4yPQHDSYYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"final probability for given words: \",ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rmYcYrY3yHl",
        "outputId": "13bdf3f1-d632-4e1c-ed55-ce38a40582a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final probability for given words:  0.08000000000000002\n"
          ]
        }
      ]
    }
  ]
}