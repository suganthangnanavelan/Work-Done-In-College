{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLR4rnnIgiqo",
        "outputId": "a27f8918-2355-4417-ef8c-908e8aa648a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "f=open(\"/content/sample.txt\",\"r\")\n",
        "text=f.read()\n",
        "text=text.lower()\n",
        "word_tokens = word_tokenize(text)\n",
        "print(word_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8RO6ZQEgeXB",
        "outputId": "01e1b0db-e84f-4f39-8735-393f526f47a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sastra', 'university', 'is', 'good', 'sastra', 'university', 'is', 'in', 'thanjavur', 'trichy', 'is', 'relatively', 'close', 'from', 'sastra', 'university', 'various', 'other', 'university', 'are', 'also', 'present', 'in', 'tamilnadu', 'sastra', 'offers', 'a', 'lot', 'of', 'courses', 'sastra', 'is', 'an', 'acronym', 'nit', 'is', 'also', 'a', 'college', 'near', 'trichy', ',', 'but', 'not', 'a', 'university']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt6BAzwcf5PK"
      },
      "outputs": [],
      "source": [
        "def collocation(w1,w2):\n",
        "  nl=list()\n",
        "  N=len(word_tokens)\n",
        "  pw1=word_tokens.count(w1)\n",
        "  pw2=word_tokens.count(w2)\n",
        "\n",
        "  Ew1w2= ((pw1*pw2)/N)  \n",
        "  Ew1nw2= ((pw1*(N-pw2))/N)\n",
        "  Enw1w2= (((N-pw1)*pw2)/N)\n",
        "  Enw1nw2= (((N-pw1)*(N-pw2)/N))\n",
        "\n",
        "  j=0\n",
        "  for i in range(len(word_tokens)-1):\n",
        "    if(word_tokens[i]==w1 and word_tokens[i+1]==w2):\n",
        "      j=j+1\n",
        "  pw12=j\n",
        "  \n",
        "  Ow1w2=pw12\n",
        "  Ow1nw2=pw1-pw12\n",
        "  Onw1w2=pw2-pw12\n",
        "  Onw1nw2=N-pw12\n",
        "\n",
        "  X= (((Ow1w2-Ew1w2)**2)/Ew1w2) + (((Ow1nw2-Ew1nw2)**2)/Ew1nw2) + (((Onw1w2-Enw1w2)**2)/Enw1w2) + (((Onw1nw2-Enw1nw2)**2)/Enw1nw2)\n",
        "  \n",
        "  if(float(X) > float(cv)):\n",
        "    #print(\"hypothesis rejected thus the given words( \",w1,\" \",w2,\" ) form a collocation\")\n",
        "    #print(X)\n",
        "    nl.append(w1)\n",
        "    nl.append(w2)\n",
        "    nl.append(X)\n",
        "  return nl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv=int(input(\"enter the critical value : \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-B4kq2of7pS",
        "outputId": "d61ad4c3-7224-4325-8079-de7c337c8e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the critical value : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcol=list()\n",
        "for i in range(len(word_tokens)-1):\n",
        "    w1=word_tokens[i]\n",
        "    w2=word_tokens[i+1]\n",
        "    fcol.append(collocation(w1,w2))\n",
        "for i in fcol:\n",
        "  if(len(i) > 1):\n",
        "    if(fcol.count(i)>1):\n",
        "      fcol.remove(i)\n",
        "  else:\n",
        "    fcol.remove(i)\n",
        "    \n",
        "for i in fcol:\n",
        "  if(len(i) > 1):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBTZtPcaf-rZ",
        "outputId": "38a7d8d6-d49c-43b9-9cdd-c0d9b506d0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'thanjavur', 22.556565656565656]\n",
            "['thanjavur', 'trichy', 22.556565656565656]\n",
            "['relatively', 'close', 46.0]\n",
            "['close', 'from', 46.0]\n",
            "['sastra', 'university', 14.952385484830458]\n",
            "['various', 'other', 46.0]\n",
            "['are', 'also', 22.556565656565656]\n",
            "['also', 'present', 22.556565656565656]\n",
            "['present', 'in', 22.556565656565656]\n",
            "['in', 'tamilnadu', 22.556565656565656]\n",
            "['offers', 'a', 14.835831180017228]\n",
            "['a', 'lot', 14.835831180017228]\n",
            "['lot', 'of', 46.0]\n",
            "['of', 'courses', 46.0]\n",
            "['an', 'acronym', 46.0]\n",
            "['acronym', 'nit', 46.0]\n",
            "['a', 'college', 14.835831180017228]\n",
            "['college', 'near', 46.0]\n",
            "['near', 'trichy', 22.556565656565656]\n",
            "['trichy', ',', 22.556565656565656]\n",
            "[',', 'but', 46.0]\n",
            "['but', 'not', 46.0]\n",
            "['not', 'a', 14.835831180017228]\n"
          ]
        }
      ]
    }
  ]
}