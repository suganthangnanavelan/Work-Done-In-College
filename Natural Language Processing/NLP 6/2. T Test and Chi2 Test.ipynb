{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7114df-da26-4d09-8d80-d7f2f6e929e2",
   "metadata": {},
   "source": [
    "# Experiment 2 :\n",
    "<b>Perform t-Test and Chi-Square test to check whether a given sequence of words is a\r\n",
    "collocation or not.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce25ae9-d862-4999-a198-0681b3aad9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import string\n",
    "\n",
    "data = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "#PREPROCESSING THE GIVEN DATA\n",
    "\n",
    "#Tokenization, stopwords removal\n",
    "sent_tokens = sent_tokenize(data)\n",
    "word_tokens = []\n",
    "for sentence in sent_tokens :\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    word_tokens += word_tokenize(sentence)\n",
    "stops = set(stopwords.words('english'))\n",
    "word_tokens = [word for word in word_tokens if word.lower() not in stops]\n",
    "\n",
    "#Frequency, Propability\n",
    "unique_words = set(word_tokens)\n",
    "print(f\"TOTAL WORDS IN THE CORPUS : {len(word_tokens)}\")\n",
    "print(f\"UNIQUE WORDS : {len(unique_words)}\")\n",
    "\n",
    "frequency = {word : word_tokens.count(word) for word in unique_words}\n",
    "propability = {word : frequency[word]/len(word_tokens) for word in unique_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fc074-8256-43e6-b57c-e62cde3b05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Bigrams, frequency and propability of bigrams\n",
    "bigrams = zip(word_tokens[:-1], word_tokens[1:])\n",
    "bigram_freq = {}\n",
    "bigram_count = 0\n",
    "for bigram in bigrams :\n",
    "    bigram_count += 1\n",
    "    if bigram in bigram_freq :\n",
    "        bigram_freq[bigram] += 1\n",
    "    else :\n",
    "        bigram_freq[bigram] = 1\n",
    "bigram_prop = {}\n",
    "for bigram, freq in bigram_freq.items() : \n",
    "    bigram_prop[bigram] = freq/bigram_count\n",
    "print(\"TOTAL UNIQUE BIGRAMS :\", len(bigram_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064f6da-7399-4e4c-aa08-4d65c37443d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import t,chi2 #For Critical value(feed value if givem)\n",
    "#T-test demonstration\n",
    "t_colloc = []\n",
    "n = len(word_tokens)\n",
    "t_critical = t.ppf(1-0.05, n-1)\n",
    "for bigram, prop in bigram_prop.items() :\n",
    "    w1, w2 = bigram\n",
    "    mu = propability[w1] * propability[w2]\n",
    "    X_ = prop\n",
    "    t_stat = (X_ - mu)/math.sqrt((X_*(1-X_))/n)\n",
    "    if t_stat > t_critical :\n",
    "        t_colloc.append(bigram)\n",
    "print(f\"{len(t_colloc)} COLLOCATIONS IN THE CORPUS DETERMINED FROM T-TEST : \\n\")\n",
    "print(t_colloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329688e7-5256-44e3-bfe2-d78a7476b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi^2 TEST demonstration\n",
    "chi_colloc = []\n",
    "n = len(word_tokens)\n",
    "chi_critical = chi2.ppf(1-0.05, 1)\n",
    "for bigram, prop in bigram_prop.items() :\n",
    "    w1, w2 = bigram\n",
    "    f1 = frequency[w1]\n",
    "    f2 = frequency[w2]\n",
    "    #Observed Frequencies\n",
    "    o_1_2 = bigram_freq[bigram]\n",
    "    o_n1_2 = f2 - o_1_2\n",
    "    o_1_n2 = f1 - o_1_2\n",
    "    o_n1_n2 = n - (o_1_2 + o_n1_2 + o_1_n2)\n",
    "    obs = [o_1_2, o_n1_2, o_1_n2, o_n1_n2]\n",
    "    #Excepcted frequencies\n",
    "    e_1_2 = (f1 * f2)/n\n",
    "    e_n1_2 = ((n - f1) * f2)/n\n",
    "    e_1_n2 = (f1 * (n - f2))/n\n",
    "    e_n1_n2 = ((n - f1)*(n - f2))/n\n",
    "    exp = [e_1_2, e_n1_2, e_1_n2, e_n1_n2]\n",
    "    chi_stat = sum( ((obs[i] - exp[i])**2)/exp[i] for i in range(4))\n",
    "    if chi_stat > chi_critical :\n",
    "        chi_colloc.append(bigram)\n",
    "print(f\"{len(chi_colloc)} COLLOCATIONS IN THE CORPUS DETERMINED FROM CHI^2-TEST : \\n\")\n",
    "print(chi_colloc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4398af-30f7-4eaa-9b2c-fe55d1974d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 15828\n",
    "f2 = 4675\n",
    "n = 14307676\n",
    "#Observed Frequencies\n",
    "o_1_2 = 8\n",
    "o_n1_2 = f2 - o_1_2\n",
    "o_1_n2 = f1 - o_1_2\n",
    "o_n1_n2 = n - (o_1_2 + o_n1_2 + o_1_n2)\n",
    "obs = [o_1_2, o_n1_2, o_1_n2, o_n1_n2]\n",
    "#Excepcted frequencies\n",
    "e_1_2 = (f1 * f2)/n\n",
    "e_n1_2 = ((n - f1) * f2)/n\n",
    "e_1_n2 = (f1 * (n - f2))/n\n",
    "e_n1_n2 = ((n - f1)*(n - f2))/n\n",
    "exp = [e_1_2, e_n1_2, e_1_n2, e_n1_n2]\n",
    "chi_stat = sum( ((obs[i] - exp[i])**2)/exp[i] for i in range(4))\n",
    "print(chi_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f065df9-3caa-4f59-94b2-5c65b0fc47d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
