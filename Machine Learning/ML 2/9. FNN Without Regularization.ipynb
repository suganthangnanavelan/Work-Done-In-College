{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15796,
     "status": "ok",
     "timestamp": 1743486879713,
     "user": {
      "displayName": "Jaison A",
      "userId": "07006398627763032071"
     },
     "user_tz": -330
    },
    "id": "S919d8O06g3w",
    "outputId": "a9c34590-8cf2-4bcc-de16-ebbea74d63b7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/content/heart_disease_uci.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "# Handle missing values - fill numeric with median, categorical with mode\n",
    "numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Impute missing values\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "df[numeric_cols] = imputer_num.fit_transform(df[numeric_cols])\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Target variable - assuming 'num' is the target (0 = no disease, >0 = disease)\n",
    "df['target'] = (df['num'] > 0).astype(int)\n",
    "\n",
    "# Select features and target\n",
    "features = numeric_cols + categorical_cols\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate different configurations\n",
    "def evaluate_model(hidden_layer_sizes, activation, max_iter=500):\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                         activation=activation,\n",
    "                         max_iter=max_iter,\n",
    "                         random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, model.loss_curve_\n",
    "\n",
    "# Test different configurations\n",
    "configurations = [\n",
    "    {\"hidden\": (10,), \"activation\": \"relu\", \"name\": \"Single(10) - ReLU\"},\n",
    "    {\"hidden\": (30,), \"activation\": \"tanh\", \"name\": \"Single(30) - Tanh\"},\n",
    "    {\"hidden\": (10, 10), \"activation\": \"relu\", \"name\": \"Double(10,10) - ReLU\"},\n",
    "    {\"hidden\": (20, 10), \"activation\": \"logistic\", \"name\": \"Double(20,10) - Logistic\"},\n",
    "    {\"hidden\": (10, 5, 3), \"activation\": \"relu\", \"name\": \"Triple(10,5,3) - ReLU\"},\n",
    "    {\"hidden\": (20, 15, 10), \"activation\": \"tanh\", \"name\": \"Triple(20,15,10) - Tanh\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "loss_curves = []\n",
    "\n",
    "for config in configurations:\n",
    "    accuracy, loss_curve = evaluate_model(config[\"hidden\"], config[\"activation\"])\n",
    "    results.append({\n",
    "        \"Configuration\": config[\"name\"],\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Activation\": config[\"activation\"],\n",
    "        \"Architecture\": str(config[\"hidden\"])\n",
    "    })\n",
    "    loss_curves.append((config[\"name\"], loss_curve))\n",
    "\n",
    "    # Print detailed report for each configuration\n",
    "    print(f\"\\nConfiguration: {config['name']}\")\n",
    "    print(\"Classification Report:\")\n",
    "    model = MLPClassifier(hidden_layer_sizes=config[\"hidden\"],\n",
    "                         activation=config[\"activation\"],\n",
    "                         max_iter=500,\n",
    "                         random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(results_df['Configuration'], results_df['Accuracy'], color='skyblue')\n",
    "plt.title('Test Accuracy by Configuration')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.xlim(0.7, 0.9)\n",
    "\n",
    "# Training loss curves\n",
    "plt.subplot(1, 2, 2)\n",
    "for name, curve in loss_curves:\n",
    "    plt.plot(curve, label=name)\n",
    "plt.title('Training Loss Across Configurations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis (using weights from the best model)\n",
    "best_config_idx = np.argmax(results_df['Accuracy'])\n",
    "best_model = MLPClassifier(hidden_layer_sizes=configurations[best_config_idx][\"hidden\"],\n",
    "                         activation=configurations[best_config_idx][\"activation\"],\n",
    "                         max_iter=500,\n",
    "                         random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the weights from input to first hidden layer\n",
    "if len(best_model.coefs_) > 0:\n",
    "    input_weights = best_model.coefs_[0]\n",
    "    feature_importance = np.mean(np.abs(input_weights), axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, feature_importance)\n",
    "    plt.title('Feature Importance (Average Absolute Weight)')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not extract feature importance - model weights not available\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPivrGG2d31eEVHX9BuG3D8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
