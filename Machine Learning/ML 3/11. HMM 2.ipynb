{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdffb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "# --- Initial Parameters ---\n",
    "start_prob = np.array([1.0, 0.0])  # Initial state probabilities (π)\n",
    "trans_mat = np.array([  # Transition matrix (A)\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "emission_prob = np.array([  # Emission matrix (B)\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.6, 0.2, 0.2]\n",
    "])\n",
    "\n",
    "# Define states and observations\n",
    "states = [\"s1\", \"s2\"]\n",
    "observations = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "# --- Create and Configure HMM ---\n",
    "# Observation sequence in numeric form (e.g., [v3, v2, v1] -> [2, 1, 0])\n",
    "observed_sequence_numeric = np.array([[2], [1], [0]])\n",
    "\n",
    "# Number of states and features (possible observations)\n",
    "n_states = len(states)\n",
    "n_features = len(observations)\n",
    "\n",
    "# Create and configure the hmmlearn model\n",
    "model = CategoricalHMM(n_components=n_states, n_features=n_features, n_iter=0, verbose=False)\n",
    "\n",
    "# Manually set the parameters after model creation\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_prob\n",
    "\n",
    "# --- 1. Forward Algorithm (Likelihood P(O|λ)) ---\n",
    "log_likelihood = model.score(observed_sequence_numeric)\n",
    "likelihood = np.exp(log_likelihood)\n",
    "\n",
    "# --- 2. Viterbi Algorithm (Most Likely Path) ---\n",
    "logprob_viterbi, best_path_indices_viterbi = model.decode(observed_sequence_numeric, algorithm=\"viterbi\")\n",
    "best_path_prob_viterbi = np.exp(logprob_viterbi)\n",
    "best_path_labels_viterbi = [states[i] for i in best_path_indices_viterbi]\n",
    "\n",
    "# --- 3. MAP Algorithm (Most Likely State Sequence) ---\n",
    "logprob_map, best_path_indices_map = model.decode(observed_sequence_numeric, algorithm=\"map\")\n",
    "best_path_prob_map = np.exp(logprob_map)\n",
    "best_path_labels_map = [states[i] for i in best_path_indices_map]\n",
    "\n",
    "# --- 4. Forward-Backward Algorithm (Posterior Probabilities) ---\n",
    "posterior_probs = model.predict_proba(observed_sequence_numeric)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"--- HMM Model Parameters ---\")\n",
    "print(f\"Start Probabilities (π): {model.startprob_}\")\n",
    "print(f\"Transition Matrix (A):\\n{model.transmat_}\")\n",
    "print(f\"Emission Matrix (B):\\n{model.emissionprob_}\")\n",
    "print(f\"Observed Sequence (Numeric): {observed_sequence_numeric.flatten()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 1. Forward Algorithm (Likelihood P(O|λ)) ---\n",
    "print(f\"--- Forward Algorithm (Likelihood P(O|λ)) ---\")\n",
    "print(f\"Log Likelihood: {log_likelihood:.6f}\")\n",
    "print(f\"Likelihood: {likelihood:.6f}\")\n",
    "print(f\"(This is the probability of observing the sequence {observations[2]}, {observations[1]}, {observations[0]} given the model)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Viterbi Algorithm (Most Likely State Sequence) ---\n",
    "print(f\"--- Viterbi Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence (Viterbi): {best_path_labels_viterbi} (Numeric: {best_path_indices_viterbi})\")\n",
    "print(f\"Log Probability of this path: {logprob_viterbi:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob_viterbi:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. MAP Algorithm (Most Likely State Sequence) ---\n",
    "print(f\"--- MAP Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence (MAP): {best_path_labels_map} (Numeric: {best_path_indices_map})\")\n",
    "print(f\"Log Probability of this path: {logprob_map:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob_map:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Forward-Backward Algorithm (Posterior Probabilities) ---\n",
    "print(f\"--- Forward-Backward Algorithm (Posterior Probabilities P(state_t|O,λ)) ---\")\n",
    "print(\"Rows = Time Steps (for observations v3, v2, v1)\")\n",
    "print(\"Columns = States [s1, s2]\")\n",
    "print(posterior_probs.round(4))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- HMM Structure Visualization ---\n",
    "\n",
    "# Create directed graph for visualization\n",
    "G = nx.DiGraph()\n",
    "for i, state in enumerate(states):\n",
    "    G.add_node(state)\n",
    "for obs in observations:\n",
    "    G.add_node(obs)\n",
    "G.add_edge('Start', states[0], weight=start_prob[0])\n",
    "G.add_edge('Start', states[1], weight=start_prob[1])\n",
    "\n",
    "# Add transitions and emissions\n",
    "for i, state_from in enumerate(states):\n",
    "    for j, state_to in enumerate(states):\n",
    "        if trans_mat[i, j] > 0:\n",
    "            G.add_edge(state_from, state_to, weight=trans_mat[i, j])\n",
    "    for j, obs in enumerate(observations):\n",
    "        if emission_prob[i, j] > 0:\n",
    "            G.add_edge(state_from, obs, weight=emission_prob[i, j])\n",
    "\n",
    "# Define node positions\n",
    "pos = {\n",
    "    'Start': (0.5, 1.1), 's1': (0.25, 0.5), 's2': (0.75, 0.5),\n",
    "    'v1': (0.1, 0.1), 'v2': (0.5, 0.1), 'v3': (0.9, 0.1)\n",
    "}\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2500, node_color='skyblue', alpha=0.6)\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "nx.draw_networkx_edges(G, pos, width=2, alpha=0.6, edge_color='gray')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'weight'), font_size=10)\n",
    "\n",
    "# Add title and display\n",
    "plt.title('HMM Structure Visualization', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd69b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4488a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e0e0c6",
   "metadata": {},
   "source": [
    "Okay, let's break down this Python code step by step.\n",
    "\n",
    "**Overall Purpose:**\n",
    "\n",
    "This code demonstrates the fundamental concepts and algorithms associated with a Hidden Markov Model (HMM). It defines a specific HMM, provides an observed sequence of outputs, and then uses the `hmmlearn` library to:\n",
    "\n",
    "1.  Calculate the **likelihood** of the observed sequence given the model (Forward Algorithm).\n",
    "2.  Find the **most probable sequence of hidden states** that generated the observation sequence (Viterbi Algorithm).\n",
    "3.  Find the sequence composed of the **most likely state at each individual time step** (MAP Algorithm, based on Forward-Backward).\n",
    "4.  Calculate the **probability of being in each hidden state at each time step**, given the entire observation sequence (Forward-Backward Algorithm).\n",
    "5.  **Visualize** the structure of the defined HMM.\n",
    "\n",
    "**Code Breakdown:**\n",
    "\n",
    "1.  **Imports:**\n",
    "    *   `numpy as np`: Used for numerical operations, especially creating and manipulating arrays (matrices and vectors) for the HMM parameters.\n",
    "    *   `matplotlib.pyplot as plt`: Used for plotting, specifically for visualizing the HMM structure.\n",
    "    *   `networkx as nx`: A library for creating, manipulating, and studying complex networks (graphs). Used here to build the HMM visualization.\n",
    "    *   `from hmmlearn.hmm import CategoricalHMM`: Imports the specific HMM class from the `hmmlearn` library suitable for discrete (categorical) observations.\n",
    "\n",
    "2.  **Initial Parameters:**\n",
    "    *   `start_prob (π)`: A NumPy array representing the initial state probabilities. `[1.0, 0.0]` means the HMM is certain to start in the first state (`s1`).\n",
    "    *   `trans_mat (A)`: A 2D NumPy array representing the transition matrix. `trans_mat[i, j]` is the probability of transitioning *from* state `i` *to* state `j`.\n",
    "        *   `[0.1, 0.9]`: From state `s1`, there's a 10% chance of staying in `s1` and a 90% chance of moving to `s2`.\n",
    "        *   `[0.5, 0.5]`: From state `s2`, there's a 50% chance of moving to `s1` and a 50% chance of staying in `s2`.\n",
    "    *   `emission_prob (B)`: A 2D NumPy array representing the emission matrix. `emission_prob[i, j]` is the probability of observing the `j`-th observation *while* in state `i`.\n",
    "        *   `[0.3, 0.5, 0.2]`: In state `s1`, P(observe `v1`)=0.3, P(observe `v2`)=0.5, P(observe `v3`)=0.2.\n",
    "        *   `[0.6, 0.2, 0.2]`: In state `s2`, P(observe `v1`)=0.6, P(observe `v2`)=0.2, P(observe `v3`)=0.2.\n",
    "\n",
    "3.  **Define States and Observations:**\n",
    "    *   `states`: A list of strings naming the hidden states (`s1`, `s2`).\n",
    "    *   `observations`: A list of strings naming the possible observations (`v1`, `v2`, `v3`).\n",
    "\n",
    "4.  **Create and Configure HMM:**\n",
    "    *   `observed_sequence_numeric`: The sequence of observations the model will analyze (`[v3, v2, v1]`). It's converted to numeric indices (`[2, 1, 0]`) because `hmmlearn` works with numerical data. Each number corresponds to the index of the observation in the `observations` list. It's reshaped into a 2D array (`[[2], [1], [0]]`) as `hmmlearn` expects sequences as column vectors (or matrices where each row is a time step).\n",
    "    *   `n_states`, `n_features`: Calculated from the lengths of the `states` and `observations` lists. These are required parameters for the `CategoricalHMM`.\n",
    "    *   `model = CategoricalHMM(...)`: Creates an instance of the `CategoricalHMM` class.\n",
    "        *   `n_components=n_states`: Specifies the number of hidden states.\n",
    "        *   `n_features=n_features`: Specifies the number of unique possible observations.\n",
    "        *   `n_iter=0`: **Crucially**, this prevents the model from trying to *learn* or *estimate* the parameters from data. We want to use the exact parameters defined earlier.\n",
    "        *   `verbose=False`: Suppresses detailed output during potential (but disabled) fitting.\n",
    "    *   `model.startprob_ = start_prob`, `model.transmat_ = trans_mat`, `model.emissionprob_ = emission_prob`: Manually setting the model's parameters to the predefined `start_prob`, `trans_mat`, and `emission_prob`. The trailing underscore (`_`) is a convention in `hmmlearn` (and `scikit-learn`) for attributes learned or set after initialization.\n",
    "\n",
    "5.  **1. Forward Algorithm (Likelihood P(O|λ)):**\n",
    "    *   `log_likelihood = model.score(observed_sequence_numeric)`: This method calculates the log-likelihood of the `observed_sequence_numeric` given the HMM model (`λ`, which represents the set of parameters π, A, B). Internally, this uses the Forward Algorithm. Working with log-likelihoods prevents numerical underflow issues with very small probabilities.\n",
    "    *   `likelihood = np.exp(log_likelihood)`: Converts the log-likelihood back to the actual probability. This value represents P(observations | model).\n",
    "\n",
    "6.  **2. Viterbi Algorithm (Most Likely Path):**\n",
    "    *   `logprob_viterbi, best_path_indices_viterbi = model.decode(observed_sequence_numeric, algorithm=\"viterbi\")`: This method finds the single most likely sequence of hidden states that could have generated the observed sequence.\n",
    "        *   `algorithm=\"viterbi\"`: Specifies the Viterbi algorithm.\n",
    "        *   `logprob_viterbi`: The log probability of this single most likely path.\n",
    "        *   `best_path_indices_viterbi`: A NumPy array containing the indices (0 or 1) of the states in the most likely path.\n",
    "    *   `best_path_prob_viterbi = np.exp(logprob_viterbi)`: Converts the log probability of the path to the actual probability.\n",
    "    *   `best_path_labels_viterbi = [states[i] for i in best_path_indices_viterbi]`: Converts the numeric state indices back to their string labels (`s1`, `s2`).\n",
    "\n",
    "7.  **3. MAP Algorithm (Most Likely State Sequence):**\n",
    "    *   `logprob_map, best_path_indices_map = model.decode(observed_sequence_numeric, algorithm=\"map\")`: This method finds the sequence of states where each state in the sequence is the *individually* most likely state at that specific time step, given the *entire* observation sequence. This is achieved by running the Forward-Backward algorithm first to calculate posterior probabilities (see step 8) and then picking the state with the highest posterior probability at each time step.\n",
    "        *   `algorithm=\"map\"`: Specifies the Maximum A Posteriori decoding based on individual state posteriors. **Note:** This path is *not guaranteed* to be the same as the Viterbi path, although it often is. Viterbi finds the globally best *sequence*, while MAP finds the sequence of locally best *states*.\n",
    "        *   `logprob_map`: The log probability associated with the MAP path (calculated differently than Viterbi's path probability).\n",
    "        *   `best_path_indices_map`: A NumPy array containing the indices of the states in the MAP path.\n",
    "    *   `best_path_prob_map = np.exp(logprob_map)`: Converts the log probability.\n",
    "    *   `best_path_labels_map = [states[i] for i in best_path_indices_map]`: Converts indices to labels.\n",
    "\n",
    "8.  **4. Forward-Backward Algorithm (Posterior Probabilities):**\n",
    "    *   `posterior_probs = model.predict_proba(observed_sequence_numeric)`: This method calculates the posterior probabilities using the Forward-Backward algorithm.\n",
    "    *   The result `posterior_probs` is a 2D NumPy array where `posterior_probs[t, i]` gives the probability of being in state `i` at time step `t`, given the *entire* observation sequence `O` and the model parameters `λ`. Mathematically, this is P(state `i` at time `t` | `O`, `λ`).\n",
    "\n",
    "9.  **Display Results:**\n",
    "    *   This section uses `print()` statements with f-strings to clearly output:\n",
    "        *   The HMM parameters that were set.\n",
    "        *   The numeric observed sequence.\n",
    "        *   The results (log-likelihood and likelihood) from the Forward algorithm.\n",
    "        *   The results (most likely path labels/indices, log probability, probability) from the Viterbi algorithm.\n",
    "        *   The results (most likely path labels/indices, log probability, probability) from the MAP algorithm.\n",
    "        *   The posterior probabilities calculated by the Forward-Backward algorithm, formatted for readability.\n",
    "\n",
    "10. **HMM Structure Visualization:**\n",
    "    *   `G = nx.DiGraph()`: Creates an empty directed graph object using `networkx`.\n",
    "    *   `G.add_node(...)`: Adds nodes to the graph representing the hidden states (`s1`, `s2`) and the possible observations (`v1`, `v2`, `v3`). A special 'Start' node is added for visualizing initial probabilities.\n",
    "    *   `G.add_edge(...)`: Adds directed edges to represent:\n",
    "        *   Initial probabilities (from 'Start' to `s1`/`s2`).\n",
    "        *   Transitions between states (`s1` to `s1`, `s1` to `s2`, etc.).\n",
    "        *   Emissions from states to observations (`s1` to `v1`, `s1` to `v2`, etc.).\n",
    "        *   The `weight` attribute of each edge stores the corresponding probability (start, transition, or emission). Edges with probability 0 are omitted.\n",
    "    *   `pos = {...}`: Manually defines the (x, y) coordinates for positioning each node in the plot for a clear layout.\n",
    "    *   `plt.figure(...)`: Creates a Matplotlib figure to draw on.\n",
    "    *   `nx.draw_networkx_nodes(...)`, `nx.draw_networkx_labels(...)`, `nx.draw_networkx_edges(...)`, `nx.draw_networkx_edge_labels(...)`: `networkx` functions (interfacing with Matplotlib) to draw the nodes, labels, edges, and edge weights (probabilities) using the defined positions.\n",
    "    *   `plt.title(...)`, `plt.axis('off')`, `plt.show()`: Standard Matplotlib commands to add a title, hide the axes, and display the plot.\n",
    "\n",
    "In summary, the code sets up a known HMM, runs standard HMM algorithms on a given observation sequence using `hmmlearn`, prints the results of these algorithms, and provides a visual representation of the HMM's structure and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e29fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fe0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e2845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c63df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e2ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad6b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f33416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef99e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d4278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab58080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997093e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189cecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9209e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd7412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a954a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fe51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2c68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40deb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f14ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075600a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed137130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474b206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac070f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Define states and observations\n",
    "states = [\"s1\", \"s2\"]\n",
    "observations = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add state and observation nodes\n",
    "G.add_nodes_from(states + observations)\n",
    "\n",
    "# Define transitions (from state to state) and emissions (from state to observation) with probabilities\n",
    "transitions = [(\"s1\", \"s1\", 0.1), (\"s1\", \"s2\", 0.9), \n",
    "               (\"s2\", \"s1\", 0.5), (\"s2\", \"s2\", 0.5)]\n",
    "emissions = [(\"s1\", \"v1\", 0.3), (\"s1\", \"v2\", 0.5), (\"s1\", \"v3\", 0.2),\n",
    "             (\"s2\", \"v1\", 0.6), (\"s2\", \"v2\", 0.2), (\"s2\", \"v3\", 0.2)]\n",
    "\n",
    "# Add edges with weights (probabilities)\n",
    "G.add_weighted_edges_from(transitions)\n",
    "G.add_weighted_edges_from(emissions)\n",
    "\n",
    "# Set node colors: states in blue, observations in green\n",
    "node_colors = ['lightblue' if node in states else 'lightgreen' for node in G.nodes]\n",
    "\n",
    "# Set position using spring layout (to avoid overlap)\n",
    "pos = nx.spring_layout(G, seed=42, k=1.5)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color=node_colors, font_size=12, font_weight='bold', arrows=True)\n",
    "\n",
    "# Draw edge labels with probabilities\n",
    "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "# Title and show\n",
    "plt.title('Hidden Markov Model with Probabilities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Define states and observations\n",
    "states = [\"s1\", \"s2\"]\n",
    "observations = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add state and observation nodes\n",
    "G.add_nodes_from(states + observations)\n",
    "\n",
    "# Define initial probabilities, transitions (state to state) and emissions (state to observation) with probabilities\n",
    "start_prob = {\"s1\": 1.0, \"s2\": 0.0}  # Initial state probabilities\n",
    "transitions = [(\"s1\", \"s1\", 0.1), (\"s1\", \"s2\", 0.9), \n",
    "               (\"s2\", \"s1\", 0.5), (\"s2\", \"s2\", 0.5)]\n",
    "emissions = [(\"s1\", \"v1\", 0.3), (\"s1\", \"v2\", 0.5), (\"s1\", \"v3\", 0.2),\n",
    "             (\"s2\", \"v1\", 0.6), (\"s2\", \"v2\", 0.2), (\"s2\", \"v3\", 0.2)]\n",
    "\n",
    "# Add edges with weights (probabilities)\n",
    "G.add_weighted_edges_from(transitions)\n",
    "G.add_weighted_edges_from(emissions)\n",
    "\n",
    "# Set node colors: states in blue, observations in green\n",
    "node_colors = ['lightblue' if node in states else 'lightgreen' for node in G.nodes]\n",
    "\n",
    "# Set position using spring layout (to avoid overlap)\n",
    "pos = nx.spring_layout(G, seed=42, k=1.5)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Draw the graph (states are in blue, observations in green)\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color=node_colors, font_size=12, font_weight='bold', arrows=True)\n",
    "\n",
    "# Draw edge labels with probabilities\n",
    "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "# Draw initial probability annotations\n",
    "start_state_label = f\"Start: s1 = {start_prob['s1']}, s2 = {start_prob['s2']}\"\n",
    "plt.text(0.5, 1.1, start_state_label, horizontalalignment='center', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "# Add transition and emission annotations for clarity\n",
    "for (start, end, prob) in transitions:\n",
    "    plt.text(pos[start][0], pos[start][1] + 0.1, f\"p={prob:.2f}\", fontsize=10, color='blue')\n",
    "\n",
    "for (state, obs, prob) in emissions:\n",
    "    plt.text(pos[state][0], pos[state][1] - 0.1, f\"p={prob:.2f}\", fontsize=10, color='green')\n",
    "\n",
    "# Title and show\n",
    "plt.title('Hidden Markov Model (HMM) Representation with Probabilities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70757e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dbfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc82f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbcf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5589e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64314504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "# Initial Parameters\n",
    "start_prob = np.array([1.0, 0.0])  # Initial state probabilities (π)\n",
    "trans_mat = np.array([  # Transition matrix (A)\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "emission_prob = np.array([  # Emission matrix (B)\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.6, 0.2, 0.2]\n",
    "])\n",
    "\n",
    "# Observation sequence in numeric form (e.g., [v3, v2, v1] -> [2, 1, 0])\n",
    "observed_sequence_numeric = np.array([[2], [1], [0]])\n",
    "\n",
    "# Define states and observations for clarity\n",
    "states = [\"s1\", \"s2\"]  # State labels\n",
    "observations = [\"v1\", \"v2\", \"v3\"]  # Observation labels\n",
    "\n",
    "# Create and configure the hmmlearn model\n",
    "model = CategoricalHMM(n_components=2, n_features=3, n_iter=0, verbose=False)\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_prob\n",
    "\n",
    "# Create directed graph for the HMM visualization\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add state nodes\n",
    "for i, state in enumerate(states):\n",
    "    G.add_node(state, label=state)\n",
    "\n",
    "# Add observation nodes\n",
    "for observation in observations:\n",
    "    G.add_node(observation, label=observation)\n",
    "\n",
    "# Add transition edges with probabilities (including self-transitions)\n",
    "for i, state_from in enumerate(states):\n",
    "    for j, state_to in enumerate(states):\n",
    "        trans_prob = trans_mat[i, j]\n",
    "        if trans_prob > 0:  # Only add edges with non-zero transition probability\n",
    "            G.add_edge(state_from, state_to, weight=trans_prob)\n",
    "\n",
    "# Add emission edges (representing each state emitting observations with their probabilities)\n",
    "for i, state in enumerate(states):\n",
    "    for j, observation in enumerate(observations):\n",
    "        emit_prob = emission_prob[i, j]\n",
    "        if emit_prob > 0:  # Only add edges with non-zero emission probability\n",
    "            G.add_edge(state, observation, weight=emit_prob)\n",
    "\n",
    "# Add the start probability edge from a virtual \"Start\" node to the initial state\n",
    "G.add_edge('Start', states[0], weight=start_prob[0])\n",
    "G.add_edge('Start', states[1], weight=start_prob[1])\n",
    "\n",
    "# Prepare edge labels (for transition and emission probabilities)\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "# Define custom positions to improve alignment\n",
    "pos = {\n",
    "    'Start': (0.5, 1.1),  # Place 'Start' at the top\n",
    "    's1': (0.25, 0.5),    # State 1 to the left\n",
    "    's2': (0.75, 0.5),    # State 2 to the right\n",
    "    'v1': (0.1, 0.1),     # Observation v1 below state 1\n",
    "    'v2': (0.5, 0.1),     # Observation v2 centered below the states\n",
    "    'v3': (0.9, 0.1)      # Observation v3 below state 2\n",
    "}\n",
    "\n",
    "# Adjust position of nodes\n",
    "for i, state in enumerate(states):\n",
    "    pos[state] = (pos[state][0], pos[state][1])  # Slightly adjust y for better vertical alignment\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2500, node_color='skyblue', alpha=0.6)\n",
    "\n",
    "# Draw state labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold', font_color='black')\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, width=2, alpha=0.6, edge_color='gray')\n",
    "\n",
    "# Draw edge labels for probabilities\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=10)\n",
    "\n",
    "# Add title\n",
    "plt.title(f'HMM Structure Visualization (Transitions and Emissions)', fontsize=16)\n",
    "plt.axis('off')  # Hide axes\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c12642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "# Initial Parameters\n",
    "start_prob = np.array([1.0, 0.0])  # Initial state probabilities (π)\n",
    "trans_mat = np.array([  # Transition matrix (A)\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "emission_prob = np.array([  # Emission matrix (B)\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.6, 0.2, 0.2]\n",
    "])\n",
    "\n",
    "# Define states and observations\n",
    "states = [\"s1\", \"s2\"]\n",
    "observations = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "# Create HMM model and assign parameters\n",
    "model = CategoricalHMM(n_components=2, n_features=3, n_iter=0)\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_prob\n",
    "\n",
    "# Create directed graph for visualization\n",
    "G = nx.DiGraph()\n",
    "for i, state in enumerate(states):\n",
    "    G.add_node(state)\n",
    "for obs in observations:\n",
    "    G.add_node(obs)\n",
    "G.add_edge('Start', states[0], weight=start_prob[0])\n",
    "G.add_edge('Start', states[1], weight=start_prob[1])\n",
    "\n",
    "# Add transitions and emissions\n",
    "for i, state_from in enumerate(states):\n",
    "    for j, state_to in enumerate(states):\n",
    "        if trans_mat[i, j] > 0:\n",
    "            G.add_edge(state_from, state_to, weight=trans_mat[i, j])\n",
    "    for j, obs in enumerate(observations):\n",
    "        if emission_prob[i, j] > 0:\n",
    "            G.add_edge(state_from, obs, weight=emission_prob[i, j])\n",
    "\n",
    "# Define node positions\n",
    "pos = {\n",
    "    'Start': (0.5, 1.1), 's1': (0.25, 0.5), 's2': (0.75, 0.5),\n",
    "    'v1': (0.1, 0.1), 'v2': (0.5, 0.1), 'v3': (0.9, 0.1)\n",
    "}\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2500, node_color='skyblue', alpha=0.6)\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "nx.draw_networkx_edges(G, pos, width=2, alpha=0.6, edge_color='gray')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'weight'), font_size=10)\n",
    "\n",
    "# Add title and display\n",
    "plt.title('HMM Structure Visualization', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750255d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8dbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ee519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "# Initial Parameters\n",
    "start_prob = np.array([1.0, 0.0])  # Initial state probabilities (π)\n",
    "trans_mat = np.array([  # Transition matrix (A)\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "emission_prob = np.array([  # Emission matrix (B)\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.6, 0.2, 0.2]\n",
    "])\n",
    "\n",
    "# Observation sequence in numeric form (e.g., [v3, v2, v1] -> [2, 1, 0])\n",
    "observed_sequence_numeric = np.array([[2], [1], [0]])\n",
    "\n",
    "# Define states and observations for clarity\n",
    "states = [\"s1\", \"s2\"]  # State labels\n",
    "observations = [\"v1\", \"v2\", \"v3\"]  # Observation labels\n",
    "\n",
    "# Number of states and features (possible observations)\n",
    "n_states = len(states)\n",
    "n_features = len(observations)\n",
    "\n",
    "# Create and configure the hmmlearn model\n",
    "model = CategoricalHMM(n_components=n_states, n_features=n_features, n_iter=0, verbose=False)\n",
    "\n",
    "# Manually set the parameters after model creation\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_prob\n",
    "\n",
    "# Print model parameters\n",
    "print(\"--- HMM Model Parameters ---\")\n",
    "print(f\"Start Probabilities (π): {model.startprob_}\")\n",
    "print(f\"Transition Matrix (A):\\n{model.transmat_}\")\n",
    "print(f\"Emission Matrix (B):\\n{model.emissionprob_}\")\n",
    "print(f\"Observed Sequence (Numeric): {observed_sequence_numeric.flatten()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 1. Forward Algorithm (Likelihood P(O|λ)) ---\n",
    "log_likelihood = model.score(observed_sequence_numeric)\n",
    "likelihood = np.exp(log_likelihood)\n",
    "\n",
    "print(f\"--- Forward Algorithm (Likelihood P(O|λ)) ---\")\n",
    "print(f\"Log Likelihood: {log_likelihood:.6f}\")\n",
    "print(f\"Likelihood: {likelihood:.6f}\")\n",
    "print(f\"(This is the probability of observing the sequence {observations[2]}, {observations[1]}, {observations[0]} given the model)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Viterbi Algorithm (Most Likely Path) ---\n",
    "logprob_viterbi, best_path_indices_viterbi = model.decode(observed_sequence_numeric, algorithm=\"viterbi\")\n",
    "best_path_prob_viterbi = np.exp(logprob_viterbi)\n",
    "best_path_labels_viterbi = [states[i] for i in best_path_indices_viterbi]\n",
    "\n",
    "print(f\"--- Viterbi Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence (Viterbi): {best_path_labels_viterbi} (Numeric: {best_path_indices_viterbi})\")\n",
    "print(f\"Log Probability of this path: {logprob_viterbi:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob_viterbi:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. MAP Algorithm (Most Likely State Sequence) ---\n",
    "logprob_map, best_path_indices_map = model.decode(observed_sequence_numeric, algorithm=\"map\")\n",
    "best_path_prob_map = np.exp(logprob_map)\n",
    "best_path_labels_map = [states[i] for i in best_path_indices_map]\n",
    "\n",
    "print(f\"--- MAP Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence (MAP): {best_path_labels_map} (Numeric: {best_path_indices_map})\")\n",
    "print(f\"Log Probability of this path: {logprob_map:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob_map:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Forward-Backward Algorithm (Posterior Probabilities) ---\n",
    "posterior_probs = model.predict_proba(observed_sequence_numeric)\n",
    "\n",
    "print(f\"--- Forward-Backward Algorithm (Posterior Probabilities P(state_t|O,λ)) ---\")\n",
    "print(\"Rows = Time Steps (for observations v3, v2, v1)\")\n",
    "print(\"Columns = States [s1, s2]\")\n",
    "print(posterior_probs.round(4))\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64012f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalHMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "start_prob = np.array([1.0, 0.0])\n",
    "\n",
    "trans_mat = np.array([\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "\n",
    "emission_prob = np.array([\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.6, 0.2, 0.2]\n",
    "])\n",
    "\n",
    "observed_sequence_numeric = np.array([[2], [1], [0]])\n",
    "\n",
    "states = [\"s1\", \"s2\"]\n",
    "observations = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "model = CategoricalHMM(n_components=len(states), n_iter=0, verbose=False)\n",
    "\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_prob\n",
    "\n",
    "print(\"--- HMM Model Parameters ---\")\n",
    "print(f\"Start Probabilities (π): {model.startprob_}\")\n",
    "print(f\"Transition Matrix (A):\\n{model.transmat_}\")\n",
    "print(f\"Emission Matrix (B):\\n{model.emissionprob_}\")\n",
    "print(f\"Observed Sequence (Numeric): {observed_sequence_numeric.flatten()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "log_likelihood = model.score(observed_sequence_numeric)\n",
    "likelihood = np.exp(log_likelihood)\n",
    "\n",
    "print(f\"--- Forward Algorithm (Likelihood P(O|λ)) ---\")\n",
    "print(f\"Log Likelihood: {log_likelihood:.6f}\")\n",
    "print(f\"Likelihood: {likelihood:.6f}\")\n",
    "print(f\"(This is the probability of observing the sequence {observations[2]}, {observations[1]}, {observations[0]} given the model)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "logprob_viterbi, best_path_indices = model.decode(observed_sequence_numeric, algorithm=\"viterbi\")\n",
    "best_path_prob = np.exp(logprob_viterbi)\n",
    "best_path_labels = [states[i] for i in best_path_indices]\n",
    "\n",
    "print(f\"--- Viterbi Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence: {best_path_labels} (Numeric: {best_path_indices})\")\n",
    "print(f\"Log Probability of this path: {logprob_viterbi:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "posterior_probs = model.predict_proba(observed_sequence_numeric)\n",
    "\n",
    "print(f\"--- Forward-Backward Algorithm (Posterior Probabilities P(state_t|O,λ)) ---\")\n",
    "print(\"Rows = Time Steps (for observations v3, v2, v1)\")\n",
    "print(\"Columns = States [s1, s2]\")\n",
    "print(posterior_probs.round(4))\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn.hmm import CategoricalHMM\n",
    "\n",
    "# --- Parameters ---\n",
    "# Define the model parameters. These include:\n",
    "# - Initial state probabilities (π)\n",
    "# - Transition matrix (A)\n",
    "# - Emission matrix (B)\n",
    "\n",
    "# Initial state probabilities (π)\n",
    "# This represents the initial distribution of the states. In our case, \n",
    "# we start with state s1 with a 100% probability and never start in state s2.\n",
    "start_prob = np.array([1.0, 0.0])  # Starting in state s1 (prob = 1)\n",
    "\n",
    "# Transition matrix (A)\n",
    "# This matrix defines the probabilities of transitioning from one state to another.\n",
    "# For example, from state s1, there's a 10% chance of staying in s1, and a 90% chance of moving to s2.\n",
    "# From state s2, there's a 50% chance of moving to s1 and a 50% chance of staying in s2.\n",
    "trans_mat = np.array([\n",
    "    [0.1, 0.9],  # Transition probabilities from state s1: P(s1 -> s1) = 0.1, P(s1 -> s2) = 0.9\n",
    "    [0.5, 0.5]   # Transition probabilities from state s2: P(s2 -> s1) = 0.5, P(s2 -> s2) = 0.5\n",
    "])\n",
    "\n",
    "# Emission matrix (B)\n",
    "# This matrix defines the probability of observing each of the observations (v1, v2, v3) \n",
    "# given the current state.\n",
    "# For example, when in state s1:\n",
    "# P(v1|s1) = 0.3, P(v2|s1) = 0.5, P(v3|s1) = 0.2\n",
    "# When in state s2:\n",
    "# P(v1|s2) = 0.6, P(v2|s2) = 0.2, P(v3|s2) = 0.2\n",
    "emission_prob = np.array([\n",
    "    [0.3, 0.5, 0.2],  # Emission probabilities for state s1: P(v1|s1) = 0.3, P(v2|s1) = 0.5, P(v3|s1) = 0.2\n",
    "    [0.6, 0.2, 0.2]   # Emission probabilities for state s2: P(v1|s2) = 0.6, P(v2|s2) = 0.2, P(v3|s2) = 0.2\n",
    "])\n",
    "\n",
    "# Observation sequence (v1=0, v2=1, v3=2)\n",
    "# We define an observation sequence [v3, v2, v1] as a numeric sequence [2, 1, 0].\n",
    "observed_sequence_numeric = np.array([[2], [1], [0]])  # Shape (n_samples, 1)\n",
    "\n",
    "# State and Observation labels (for clarity)\n",
    "states = [\"s1\", \"s2\"]  # Two hidden states: s1 and s2\n",
    "observations = [\"v1\", \"v2\", \"v3\"]  # Three possible observations: v1, v2, v3\n",
    "\n",
    "# --- Create and Configure hmmlearn Model ---\n",
    "# Initialize the HMM model with 2 components (states).\n",
    "# n_iter=0 means we are not training the model, we are directly assigning the parameters.\n",
    "model = CategoricalHMM(n_components=len(states), n_iter=0, verbose=False)\n",
    "\n",
    "# Set the model parameters\n",
    "model.startprob_ = start_prob  # Set the initial state probabilities (π)\n",
    "model.transmat_ = trans_mat    # Set the transition matrix (A)\n",
    "model.emissionprob_ = emission_prob  # Set the emission matrix (B)\n",
    "print(model.startprob_,model.transmat_,model.emissionprob_,sep='\\n')\n",
    "# --- Print Model Parameters ---\n",
    "print(\"--- HMM Model Parameters ---\")\n",
    "print(f\"Start Probabilities (π): {model.startprob_}\")\n",
    "print(f\"Transition Matrix (A):\\n{model.transmat_}\")\n",
    "print(f\"Emission Matrix (B):\\n{model.emissionprob_}\")\n",
    "print(f\"Observed Sequence (Numeric): {observed_sequence_numeric.flatten()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 1. Forward Algorithm (Likelihood P(O|λ)) ---\n",
    "# The Forward algorithm calculates the likelihood of observing the sequence of events (O)\n",
    "# given the model parameters (λ). It is internally implemented in model.score().\n",
    "log_likelihood = model.score(observed_sequence_numeric)  # Log-likelihood of the observation sequence\n",
    "likelihood = np.exp(log_likelihood)  # Convert log-likelihood to probability\n",
    "\n",
    "# Print the result of the Forward Algorithm\n",
    "print(f\"--- Forward Algorithm (Likelihood P(O|λ)) ---\")\n",
    "print(f\"Log Likelihood: {log_likelihood:.6f}\")\n",
    "print(f\"Likelihood: {likelihood:.6f}\")\n",
    "print(f\"(This is the probability of observing the sequence {observations[2]}, {observations[1]}, {observations[0]} given the model)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Viterbi Algorithm (Most Likely State Sequence) ---\n",
    "# The Viterbi algorithm is used to find the most likely sequence of hidden states \n",
    "# that could have generated the observed sequence.\n",
    "# The model.decode() function applies the Viterbi algorithm.\n",
    "logprob_viterbi, best_path_indices = model.decode(observed_sequence_numeric, algorithm=\"viterbi\")\n",
    "best_path_prob = np.exp(logprob_viterbi)  # Convert log-probability to normal probability\n",
    "best_path_labels = [states[i] for i in best_path_indices]  # Convert numeric indices to state labels\n",
    "\n",
    "# Print the result of the Viterbi Algorithm\n",
    "print(f\"--- Viterbi Algorithm (Most Likely State Sequence) ---\")\n",
    "print(f\"Most Likely Hidden State Sequence: {best_path_labels} (Numeric: {best_path_indices})\")\n",
    "print(f\"Log Probability of this path: {logprob_viterbi:.6f}\")\n",
    "print(f\"Probability of this path: {best_path_prob:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. Forward-Backward Algorithm (Posterior Probabilities) ---\n",
    "# The Forward-Backward algorithm calculates the posterior probabilities of the hidden states\n",
    "# at each time step, given the entire observed sequence. This is done using model.predict_proba().\n",
    "posterior_probs = model.predict_proba(observed_sequence_numeric)\n",
    "\n",
    "# Print the result of the Forward-Backward Algorithm\n",
    "print(f\"--- Forward-Backward Algorithm (Posterior Probabilities P(state_t|O,λ)) ---\")\n",
    "print(\"Rows = Time Steps (for observations v3, v2, v1)\")\n",
    "print(\"Columns = States [s1, s2]\")\n",
    "print(posterior_probs.round(4))  # Rounded for readability\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# You can verify that sum(posterior_probs[t,:]) == 1.0 for each time step t (since it's a probability distribution).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
