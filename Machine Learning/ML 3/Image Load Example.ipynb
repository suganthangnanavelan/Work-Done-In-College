{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543e45d-329e-424f-81fd-ac03a07933d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct, gzip, numpy as np\n",
    "\n",
    "def _smart_open(path):\n",
    "    # transparently handle .gz files\n",
    "    return gzip.open(path, 'rb') if path.endswith('.gz') else open(path, 'rb')\n",
    "\n",
    "def find_file(base_path, fname):\n",
    "    \"\"\"Return the real file, no matter how Kaggle wrapped it.\"\"\"\n",
    "    direct = os.path.join(base_path, fname)                 # /â€¦/fname\n",
    "    wrapped = os.path.join(base_path, fname, fname)         # /â€¦/fname/fname\n",
    "    for p in (direct, direct + '.gz', wrapped, wrapped + '.gz'):\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    raise FileNotFoundError(f'{fname} not found under {base_path}')\n",
    "\n",
    "def load_images(path):\n",
    "    with _smart_open(path) as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        rows, cols  = struct.unpack(\">II\", f.read(8))\n",
    "        data = np.frombuffer(f.read(rows * cols * size), dtype=np.uint8)\n",
    "        return data.reshape(size, rows * cols)\n",
    "\n",
    "def load_labels(path):\n",
    "    with _smart_open(path) as f:\n",
    "        _, size = struct.unpack(\">II\", f.read(8))\n",
    "        return np.frombuffer(f.read(size), dtype=np.uint8)\n",
    "\n",
    "def load_mnist_data(base_path):\n",
    "    X_train = load_images(find_file(base_path, 'train-images-idx3-ubyte'))\n",
    "    y_train = load_labels(find_file(base_path, 'train-labels-idx1-ubyte'))\n",
    "    X_test  = load_images(find_file(base_path, 't10k-images-idx3-ubyte'))\n",
    "    y_test  = load_labels(find_file(base_path, 't10k-labels-idx1-ubyte'))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_mnist_data(mnist_dataset_path)\n",
    "print(X_train.shape, y_train.shape)   # (60000, 784) (60000,)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def load_images_from_folder(folder_path, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(folder_path))  # Assuming one folder per class\n",
    "\n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(folder_path, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(class_folder):\n",
    "            img_path = os.path.join(class_folder, filename)\n",
    "            try:\n",
    "                img = load_img(img_path, target_size=img_size)\n",
    "                img_array = img_to_array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(label_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    images = np.array(images, dtype=\"float32\") / 255.0  # Normalize to [0,1]\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_names\n",
    "\n",
    "def split_data(images, labels, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        images, labels, test_size=test_size, random_state=random_state, stratify=labels\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'your/folder/path'  # ðŸ”¥ Example: './dataset/'\n",
    "img_size = (128, 128)  # ðŸ”¥ Resize images to 128x128\n",
    "\n",
    "images, labels, class_names = load_images_from_folder(folder_path, img_size)\n",
    "X_train, X_test, y_train, y_test = split_data(images, labels)\n",
    "\n",
    "print(f\"Train set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Class names: {class_names}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
